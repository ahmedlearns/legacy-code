<!DOCTYPE html>
<html>
  <head>
    <title>Title</title>
    <meta charset="utf-8">
    <style>
      @import url(https://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
      @import url(https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);
      @import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);

      body { font-family: 'Droid Serif'; }
      h1, h2, h3 {
        font-family: 'Yanone Kaffeesatz';
        font-weight: normal;
      }
      .remark-code, .remark-inline-code { font-family: 'Ubuntu Mono'; }
    </style>
  </head>
  <body>
    <textarea id="source">

class: center, middle

# Working with Legacy Code

<br>
<br>
<br>
<br>
<br>
<span style="color: gray"><sub><sup>Ahmed Ismail</sup></sub></span>


---

class: center

# What is Legacy Code?

<img src="https://i.imgur.com/1r2x3C6.jpg" width="250"/>

???
Any ideas?

Without tests, no matter how well written it is, pretty, objected-oriented, or well encapsulated it is,

we can't change the behavior of our code quickly and verifiably. We can't be certain within a reasonable timeframe if our code is getting better or worse.

--

Code we've gotten from someone else

--

Code that hasn't been touched in living memory

--

Code you're afraid to touch


--

Code written by someone who is no longer around

--

Code without tests

---

class: center

# Clean Code

<img src="https://i.imgur.com/igYy5Y5.png" width="250" />

???
Any ideas?

--

Easy to understand

--

Easy to get under test

--

Easy to refactor

--

Easy to add features

---

class: center

# Changing Software

--

## Questions to ask yourself:

<br />

--

1. .left[What changes do we have to make?]

--

2. .left[How will we know that we've done them correctly?]

--

3. .left[How will we know that we haven't broken anything?]

--

4. .left[How much change can you afford if changes are risky?]

---

class: center, middle

# "If it's not broke, don't fix it."

???
It's tempting to think that we can minimize software problems and bugs by avoiding them, but, unfortunately, it always catches up with us.

Avoiding creating new classes and methods leads to giganto-hard-to-understand-and-modify systems.

---

class: center

# Sunk Cost Fallacy

<img src="https://i.pinimg.com/originals/76/18/e1/7618e1ebf2c62f6270441eeeb1e03e52.png" width="400">


???
When you continue a behavior as a result of the previously invested time, money, or effort.

Examples:

Over-eating to get your money's worth when you order too much food.

Driving through a blizzard to get to a concert you paid $20 for.

"If the costs outweigh the benefits, the extra costs incurred (inconvenience, time or even money) are held in a different mental account than the one associated with the original work, transaction, etc."

---

class: center

# Two Ways to Change Code

--

## Cover and Move

--

and

## Edit and Pray

---

class: center

# Edit and Pray

--

<img src="https://energycentral.com/sites/default/files/styles/article_body/public/ece/nodes/355107/safety20net.png" width="450">

Industry standard?

???
Carefully plan changes <br />
Make sure you understand code <br />
Make the changes

---

class: center

# Cover and Move

--

<img src="https://www.huaxingnets.com/wp-content/uploads/2018/06/tech_safety_alpha.png" width="450" />


Work with a safety net.

???
Cover = cover with tests. <br />
We can make quick changes and find out very quickly if the effects were good or bad. <br />

---

class: center

# Software Vise

<br>

<img src="https://images-na.ssl-images-amazon.com/images/I/61A18RWrAmL._AC_SY450_.jpg" width="450">

**vise** *noun* a metal tool with movable jaws that are used to hold an object firmly in place while work is done on it, typically attached to a workbench.

???
Tests that detect change are like a vise around our code <br>

The behavior of the code is fixed in place <br>

Allowing us to be in more control of our work.

---

class: center

# The Legacy Code Dilemma

<img src="https://imgs.xkcd.com/comics/delicious.png" width="350">

--

???
In order to make changes easier, often we have to break dependencies <br>

--

When we change code, we should have tests in place.

--

To put tests in place, we often have to change code.

--

What do we do?

Ehh. Be careful. Use your refactoring tools.

---

class: center

# (one) Legacy Code Change Algorithm

--

1. .left[Identify change points.]

--

1. .left[Find test points.]

--

1. .left[Break dependencies.]

--

1. .left[Write tests.]

--

1. .left[Make changes (and refactor).]

--

1. .left[<sup><sub>profit???</sub></sup>]


---

class: center

# What else can we do?

<br>

???
Any ideas?

A broad test that covers a large swath of the application will help you notice if any of your changes break something.

Since you have finite time to spend writing tests, it is more important to get broad coverage than targeted coverage.

<br>

Usually TDD writes just enough test code to make the tests fail; then writes model code only until all tests pass.

When working with legacy code, the model code is mostly already written.

Not uncommon to write a lot of tests before switching back to model code.

--

Focus more on broad coverage than targeted coverage.

--

Write a lot of tests before you can write a little.

--

Already have some manual tests? Can they be automated?

--

Already have some functional/acceptance/integration tests? <br>
Can they be morphed into unit tests?

---

class: center

# Working with Legacy Code

<img src="https://f4.bcbits.com/img/a0897681528_10.jpg" width="350">

--

= how do we break dependencies?


---

class: center

# Breaking Dependencies

<img src="https://live.mrf.io/statics/i/ps/lrmonline.com/wp-content/uploads/2017/09/Motherboy.jpg" width="450">

???

Dependencies can be problematic, but, fortunately we can break them.

---

class: center

# I Can't Get This Class into a Test Harness

--

## Bringing a dependency into a test is hard.

--

Objects can't be instantiated easily.

--

The test refuses to build with the class in it.

--

The constructor we need to use does some wonky stuff.

--

The tests cannot currently *sense* what's happening in the 50-line constructor.


???
Test Harness: enabler that does the work of executing tests via a test library, and also generates an output (e.g. a report).

This includes your test data and your test scenarios.

Essentially, you have a complete test harness when I can click a button or run a command to execute all of your tests and generate a report.

---

# The Case of the Irritating Parameter

--

```
public class CreditValidator {

  public CreditValidator(ReporterConnection connection,
                        CreditMaster master,
                        String validatorId) {
    ...
  }

  ValidationCertificate validateCustomer(Customer customer)
      throws InvalidCreditException {
    ...
  }
}
```

--

Mission: Add a method, `getValidationPercent`, to tell us the percentage of `validateCustomer` calls we've made over the life of a `CreditValidator`.

--

<br>
<br>

How do we get started?

---

## Just Try It

--

```
public void testCanCreateValidator() {
  CreditValidator validator = new CreditValidator();
}
```

--

<br>
Best way to see if you can instantiate a class in a test is to just try to do it.

--

The compiler will do part of the work for you by telling you want you need to make it work.

???
Construction tests look a little weird. They don't have an assertion.

Later on, when the object can be instantiated, the test can be repurposed to do something more meaningful.

---

## Digging Deeper

--

```
public class ReporterConnection {

  public ReporterConnection(int port, String username, String password)
      throws IOException {
    ...
  }
}
```

--

```
public class CreditMaster {

  public CreditMaster(String filename, boolean isLocal) {
    ...
  }
}

```

???

When a connection is constructed, it connects with a server. It uses that connection to then retrieve reports needed to validate a customer's credit.

CreditMaster gives us policy info that we can use in some credit decisions. It can load info from a spreadsheet and holds it in memory for us.

---

## So we just create these objects, right?

```
public void testCanCreateValidator() {
  ReporterConnection connection =
    new ReporterConnection(DEFAULT_PORT, "admin", "m4d$ki11s");

  CreditMaster master = new CreditMaster("customers.csv", true);

  CreditValidator validator =
    new CreditValidator(connection, master, "a1234");
}

```

--

<br>
What's wrong with this picture?

???

Creating a connection to a server is not a good idea. Why?

Unit tests only tests the system under test (the constructor).

Besides, it can take too long to get a connection, and the server may not always be available.

---

## What can we do instead?

--

There are many ways to go about this.

--

Mocking / stubbing have become a popular method.

--

...but be careful with mocking.

---

## On Mocking

--

Assuming we want a unit test to test a single codepath through a single method.

--

You will need to mock every dependency that your unit test touches.

--

Though that may sound good, if you're not careful, you'll spend all your time mocking dependencies, which can in turn unintentionally make your tests more complicated and probably even fragile.

--

TL;DR: unit tests should test a cohesive unit, which can be more than a single method, IMHO

???
Mock objects are good when you want to test interactions. You can test to see if a function was called.

This can become problematic when you end up testing interactions even when not necessary.

(provide example? https://stackoverflow.com/a/38260 ----- probably warrants it's own slide).

We are really using the mock as a stub.

I'm sure we can sit here and talk about when and where to use mock objects, but let's get back to it.

---

## Back to the program

--

```
public void testCanCreateValidator() {
  ReporterConnection connection = mock(ReporterConnection.class);

  CreditMaster master = mock(CreditMaster.class);

  CreditValidator validator =
    new CreditValidator(connection, master, "a1234");
}

```

---

## Extract Interface

???

Mock objects are overkill in this case - we don't need to test the interaction of a validator and a connection right now.

---

class: center

# Resources

<img src="https://images-na.ssl-images-amazon.com/images/I/51ya8wirXeL._SX375_BO1,204,203,200_.jpg" width="250">

???
Podcasts, articles, blogs, videos, katas, etc.

---

class: center

# Katas

--

[Trip Service](https://github.com/sandromancuso/trip-service-kata)

--

[Trivia](https://github.com/jbrains/trivia)

--

[Legacy Train](https://github.com/42skillz/liveCoding-LegacyTrain)

--

[Birthday Greetings](https://github.com/xpmatteo/birthday-greetings-kata)

--

And of course, [Gilded Rose](https://github.com/emilybache/GildedRose-Refactoring-Kata)

--

[<sub><sup><sub>*Fifty Shades of Legacy Goose Game*</sub></sup></sub>](https://github.com/xpepper/fifty-shades-of-legacy-goose-game)

---


class: center

# Summing it Up

--

Some tests are better than none

--

Don't let the perfect be the enemy of good.



    </textarea>
    <script src="https://remarkjs.com/downloads/remark-latest.min.js">
    </script>
    <script>
      var slideshow = remark.create();
    </script>
  </body>
</html>